{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceType":"competition","sourceId":99552,"databundleVersionId":13851420},{"sourceType":"datasetVersion","sourceId":12780021,"datasetId":8079690,"databundleVersionId":13404554}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Pipeline\n1. **DICOM → 3D Volume**: Normalize to `(32, 384, 384)`\n2. **EfficientNetV2-S**: 32-channel input, 14 binary outputs\n3. **Ensemble**: Average 5-fold predictions","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pydicom\nimport cv2\nfrom pathlib import Path\nfrom typing import List, Tuple, Dict, Optional\nfrom scipy import ndimage\nimport warnings\nimport gc\nwarnings.filterwarnings('ignore')\n\nclass DICOMPreprocessorKaggle:\n    \"\"\"\n    DICOM preprocessing system for Kaggle Code Competition\n    Converts original DICOMPreprocessor logic to single series processing\n    \"\"\"\n    \n    def __init__(self, target_shape: Tuple[int, int, int] = (32, 384, 384)):\n        self.target_depth, self.target_height, self.target_width = target_shape\n        \n    def load_dicom_series(self, series_path: str) -> Tuple[List[pydicom.Dataset], str]:\n        \"\"\"\n        Load DICOM series\n        \"\"\"\n        series_path = Path(series_path)\n        series_name = series_path.name\n        \n        # Search for DICOM files\n        dicom_files = []\n        for root, _, files in os.walk(series_path):\n            for file in files:\n                if file.endswith('.dcm'):\n                    dicom_files.append(os.path.join(root, file))\n        \n        if not dicom_files:\n            raise ValueError(f\"No DICOM files found in {series_path}\")\n        \n        #print(f\"Found {len(dicom_files)} DICOM files in series {series_name}\")\n        \n        # Load DICOM datasets\n        datasets = []\n        for filepath in dicom_files:\n            try:\n                ds = pydicom.dcmread(filepath, force=True)\n                datasets.append(ds)\n            except Exception as e:\n                #print(f\"Failed to load {filepath}: {e}\")\n                continue\n        \n        if not datasets:\n            raise ValueError(f\"No valid DICOM files in {series_path}\")\n        \n        return datasets, series_name\n    \n    def extract_slice_info(self, datasets: List[pydicom.Dataset]) -> List[Dict]:\n        \"\"\"\n        Extract position information for each slice\n        \"\"\"\n        slice_info = []\n        \n        for i, ds in enumerate(datasets):\n            info = {\n                'dataset': ds,\n                'index': i,\n                'instance_number': getattr(ds, 'InstanceNumber', i),\n            }\n            \n            # Get z-coordinate from ImagePositionPatient\n            try:\n                position = getattr(ds, 'ImagePositionPatient', None)\n                if position is not None and len(position) >= 3:\n                    info['z_position'] = float(position[2])\n                else:\n                    # Fallback: use InstanceNumber\n                    info['z_position'] = float(info['instance_number'])\n                    #print(\"ImagePositionPatient not found, using InstanceNumber\")\n            except Exception as e:\n                info['z_position'] = float(i)\n                #print(f\"Failed to extract position info: {e}\")\n            \n            slice_info.append(info)\n        \n        return slice_info\n    \n    def sort_slices_by_position(self, slice_info: List[Dict]) -> List[Dict]:\n        \"\"\"\n        Sort slices by z-coordinate\n        \"\"\"\n        # Sort by z-coordinate\n        sorted_slices = sorted(slice_info, key=lambda x: x['z_position'])\n        \n        #print(f\"Sorted {len(sorted_slices)} slices by z-position\")\n        #print(f\"Z-range: {sorted_slices[0]['z_position']:.2f} to {sorted_slices[-1]['z_position']:.2f}\")\n        \n        return sorted_slices\n    \n    def get_windowing_params(self, ds: pydicom.Dataset, img: np.ndarray = None) -> Tuple[Optional[float], Optional[float]]:\n        \"\"\"\n        Get windowing parameters based on modality\n        \"\"\"\n        modality = getattr(ds, 'Modality', 'CT')\n        \n        if modality == 'CT':\n            # For CT, apply CTA (angiography) settings\n            center, width = (50, 350)\n            #print(f\"Using CTA windowing for CT: Center={center}, Width={width}\")\n            # return center, width\n            return \"CT\", \"CT\"\n            \n        elif modality == 'MR':\n            # For MR, skip windowing (statistical normalization only)\n            #print(\"MR modality detected: skipping windowing, using statistical normalization\")\n            return None, None\n            \n        else:\n            # Unexpected modality (safety measure)\n            #print(f\"Unexpected modality '{modality}', using CTA windowing\")\n            #return (50, 350)\n            return None, None\n    \n    def apply_windowing_or_normalize(self, img: np.ndarray, center: Optional[float], width: Optional[float]) -> np.ndarray:\n        \"\"\"\n        Apply windowing or statistical normalization\n        \"\"\"\n        if center is not None and width is not None:\n            # # Windowing processing (for CT/CTA)\n            # img_min = center - width / 2\n            # img_max = center + width / 2\n            \n            # windowed = np.clip(img, img_min, img_max)\n            # windowed = (windowed - img_min) / (img_max - img_min + 1e-7)\n            # result = (windowed * 255).astype(np.uint8)\n            \n            # #print(f\"Applied windowing: [{img_min:.1f}, {img_max:.1f}] → [0, 255]\")\n            # return result\n            \n            # Statistical normalization (for CT as well)\n            # Normalize using 1-99 percentiles\n            p1, p99 = np.percentile(img, [1, 99])\n            p1, p99 = 0, 500\n            \n            if p99 > p1:\n                normalized = np.clip(img, p1, p99)\n                normalized = (normalized - p1) / (p99 - p1)\n                result = (normalized * 255).astype(np.uint8)\n                \n                #print(f\"Applied statistical normalization: [{p1:.1f}, {p99:.1f}] → [0, 255]\")\n                return result\n            else:\n                # Fallback: min-max normalization\n                img_min, img_max = img.min(), img.max()\n                if img_max > img_min:\n                    normalized = (img - img_min) / (img_max - img_min)\n                    result = (normalized * 255).astype(np.uint8)\n                    #print(f\"Applied min-max normalization: [{img_min:.1f}, {img_max:.1f}] → [0, 255]\")\n                    return result\n                else:\n                    # If image has no variation\n                    #print(\"Image has no variation, returning zeros\")\n                    return np.zeros_like(img, dtype=np.uint8)\n        \n        else:\n            # Statistical normalization (for MR)\n            # Normalize using 1-99 percentiles\n            p1, p99 = np.percentile(img, [1, 99])\n            \n            if p99 > p1:\n                normalized = np.clip(img, p1, p99)\n                normalized = (normalized - p1) / (p99 - p1)\n                result = (normalized * 255).astype(np.uint8)\n                \n                #print(f\"Applied statistical normalization: [{p1:.1f}, {p99:.1f}] → [0, 255]\")\n                return result\n            else:\n                # Fallback: min-max normalization\n                img_min, img_max = img.min(), img.max()\n                if img_max > img_min:\n                    normalized = (img - img_min) / (img_max - img_min)\n                    result = (normalized * 255).astype(np.uint8)\n                    #print(f\"Applied min-max normalization: [{img_min:.1f}, {img_max:.1f}] → [0, 255]\")\n                    return result\n                else:\n                    # If image has no variation\n                    #print(\"Image has no variation, returning zeros\")\n                    return np.zeros_like(img, dtype=np.uint8)\n    \n    def extract_pixel_array(self, ds: pydicom.Dataset) -> np.ndarray:\n        \"\"\"\n        Extract 2D pixel array from DICOM and apply preprocessing (for 2D DICOM series)\n        \"\"\"\n        # Get pixel data\n        img = ds.pixel_array.astype(np.float32)\n        \n        # For 3D volume case (multiple frames) - select middle frame\n        if img.ndim == 3:\n            #print(f\"3D DICOM in 2D processing - using middle frame from shape: {img.shape}\")\n            frame_idx = img.shape[0] // 2\n            img = img[frame_idx]\n            #print(f\"Selected frame {frame_idx} from 3D DICOM\")\n        \n        # Convert color image to grayscale\n        if img.ndim == 3 and img.shape[-1] == 3:\n            img = cv2.cvtColor(img.astype(np.uint8), cv2.COLOR_RGB2GRAY).astype(np.float32)\n            #print(\"Converted color image to grayscale\")\n        \n        # Apply RescaleSlope and RescaleIntercept\n        slope = getattr(ds, 'RescaleSlope', 1)\n        intercept = getattr(ds, 'RescaleIntercept', 0)\n        slope, intercept = 1, 0\n        if slope != 1 or intercept != 0:\n            img = img * float(slope) + float(intercept)\n            #print(f\"Applied rescaling: slope={slope}, intercept={intercept}\")\n        \n        return img\n    \n    def resize_volume_3d(self, volume: np.ndarray) -> np.ndarray:\n        \"\"\"\n        Resize 3D volume to target size\n        \"\"\"\n        current_shape = volume.shape\n        target_shape = (self.target_depth, self.target_height, self.target_width)\n        \n        if current_shape == target_shape:\n            return volume\n        \n        #print(f\"Resizing volume from {current_shape} to {target_shape}\")\n        \n        # 3D resizing using scipy.ndimage\n        zoom_factors = [\n            target_shape[i] / current_shape[i] for i in range(3)\n        ]\n        \n        # Resize with linear interpolation\n        resized_volume = ndimage.zoom(volume, zoom_factors, order=1, mode='nearest')\n        \n        # Clip to exact size just in case\n        resized_volume = resized_volume[:self.target_depth, :self.target_height, :self.target_width]\n        \n        # Padding if necessary\n        pad_width = [\n            (0, max(0, self.target_depth - resized_volume.shape[0])),\n            (0, max(0, self.target_height - resized_volume.shape[1])),\n            (0, max(0, self.target_width - resized_volume.shape[2]))\n        ]\n        \n        if any(pw[1] > 0 for pw in pad_width):\n            resized_volume = np.pad(resized_volume, pad_width, mode='edge')\n        \n        #print(f\"Final volume shape: {resized_volume.shape}\")\n        return resized_volume.astype(np.uint8)\n    \n    def process_series(self, series_path: str) -> np.ndarray:\n        \"\"\"\n        Process DICOM series and return as NumPy array (for Kaggle: no file saving)\n        \"\"\"\n        try:\n            # 1. Load DICOM files\n            datasets, series_name = self.load_dicom_series(series_path)\n            \n            # Check first DICOM to determine 3D/2D\n            first_ds = datasets[0]\n            first_img = first_ds.pixel_array\n            \n            if len(datasets) == 1 and first_img.ndim == 3:\n                # Case 1: Single 3D DICOM file\n                #print(f\"Processing single 3D DICOM with shape: {first_img.shape}\")\n                return self._process_single_3d_dicom(first_ds, series_name)\n            else:\n                # Case 2: Multiple 2D DICOM files\n                #print(f\"Processing {len(datasets)} 2D DICOM files\")\n                return self._process_multiple_2d_dicoms(datasets, series_name)\n            \n        except Exception as e:\n            #print(f\"Failed to process series {series_path}: {e}\")\n            raise\n    \n    def _process_single_3d_dicom(self, ds: pydicom.Dataset, series_name: str) -> np.ndarray:\n        \"\"\"\n        Process single 3D DICOM file (for Kaggle: no file saving)\n        \"\"\"\n        # Get pixel array\n        volume = ds.pixel_array.astype(np.float32)\n        \n        # Apply RescaleSlope and RescaleIntercept\n        slope = getattr(ds, 'RescaleSlope', 1)\n        intercept = getattr(ds, 'RescaleIntercept', 0)\n        slope, intercept = 1, 0\n        if slope != 1 or intercept != 0:\n            volume = volume * float(slope) + float(intercept)\n            # #print(f\"Applied rescaling: slope={slope}, intercept={intercept}\")\n        \n        # Get windowing settings\n        window_center, window_width = self.get_windowing_params(ds)\n        \n        # Apply windowing to each slice\n        processed_slices = []\n        for i in range(volume.shape[0]):\n            slice_img = volume[i]\n            processed_img = self.apply_windowing_or_normalize(slice_img, window_center, window_width)\n            processed_slices.append(processed_img)\n        \n        volume = np.stack(processed_slices, axis=0)\n        ##print(f\"3D volume shape after windowing: {volume.shape}\")\n        \n        # 3D resize\n        final_volume = self.resize_volume_3d(volume)\n        \n        ##print(f\"Successfully processed 3D DICOM series {series_name}\")\n        return final_volume\n    \n    def _process_multiple_2d_dicoms(self, datasets: List[pydicom.Dataset], series_name: str) -> np.ndarray:\n        \"\"\"\n        Process multiple 2D DICOM files (for Kaggle: no file saving)\n        \"\"\"\n        slice_info = self.extract_slice_info(datasets)\n        sorted_slices = self.sort_slices_by_position(slice_info)\n        first_img = self.extract_pixel_array(sorted_slices[0]['dataset'])\n        window_center, window_width = self.get_windowing_params(sorted_slices[0]['dataset'], first_img)\n        processed_slices = []\n        \n        for slice_data in sorted_slices:\n            ds = slice_data['dataset']\n            img = self.extract_pixel_array(ds)\n            processed_img = self.apply_windowing_or_normalize(img, window_center, window_width)\n            resized_img = cv2.resize(processed_img, (self.target_width, self.target_height))\n            \n            processed_slices.append(resized_img)\n\n        volume = np.stack(processed_slices, axis=0)\n        ##print(f\"2D slices stacked to volume shape: {volume.shape}\")\n        final_volume = self.resize_volume_3d(volume)\n        \n        ##print(f\"Successfully processed 2D DICOM series {series_name}\")\n        return final_volume\n\ndef process_dicom_series_kaggle(series_path: str, target_shape: Tuple[int, int, int] = (32, 384, 384)) -> np.ndarray:\n    \"\"\"\n    DICOM processing function for Kaggle inference (single series)\n    \n    Args:\n        series_path: Path to DICOM series\n        target_shape: Target volume size (depth, height, width)\n    \n    Returns:\n        np.ndarray: Processed volume\n    \"\"\"\n    preprocessor = DICOMPreprocessorKaggle(target_shape=target_shape)\n    return preprocessor.process_series(series_path)\n\n# Safe processing function with memory cleanup\ndef process_dicom_series_safe(series_path: str, target_shape: Tuple[int, int, int] = (32, 384, 384)) -> np.ndarray:\n    \"\"\"\n    Safe DICOM processing with memory cleanup\n    \n    Args:\n        series_path: Path to DICOM series\n        target_shape: Target volume size (depth, height, width)\n    \n    Returns:\n        np.ndarray: Processed volume\n    \"\"\"\n    try:\n        volume = process_dicom_series_kaggle(series_path, target_shape)\n        return volume\n    finally:\n        # Memory cleanup\n        gc.collect()\n\n# Test function\ndef test_single_series(series_path: str, target_shape: Tuple[int, int, int] = (32, 384, 384)):\n    \"\"\"\n    Test processing for single series\n    \"\"\"\n    try:\n        #print(f\"Testing single series: {series_path}\")\n        \n        # Execute processing\n        volume = process_dicom_series_safe(series_path, target_shape)\n        \n        # Display results\n        print(f\"✓ Successfully processed series\")\n        #print(f\"  Volume shape: {volume.shape}\")\n        #print(f\"  Volume dtype: {volume.dtype}\")\n        #print(f\"  Volume range: [{volume.min()}, {volume.max()}]\")\n        \n        return volume\n        \n    except Exception as e:\n        #print(f\"✗ Failed to process series: {e}\")\n        return None","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-07T20:16:12.567474Z","iopub.execute_input":"2025-12-07T20:16:12.567764Z","iopub.status.idle":"2025-12-07T20:16:12.597248Z","shell.execute_reply.started":"2025-12-07T20:16:12.567741Z","shell.execute_reply":"2025-12-07T20:16:12.596705Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"import sys\nimport gc\nimport json\nimport shutil\nimport warnings\nwarnings.filterwarnings('ignore')\nfrom pathlib import Path\nfrom typing import List, Dict, Optional, Tuple\n\n# Data handling\nimport numpy as np\nimport polars as pl\nimport pandas as pd\n\n# Medical imaging\nimport pydicom\nimport cv2\n\n# ML/DL\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.cuda.amp import autocast\nimport timm\n\n# Transformations\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\n\n# Competition API\nimport kaggle_evaluation.rsna_inference_server\n\n# DICOM preprocessor (DICOMPreprocessorKaggle class defined in previous cell)\n# In actual use, define in the same file or import appropriately\n\n# Set device\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n#print(f\"Using device: {device}\")\n\n# ====================================================\n# Competition constants\n# ====================================================\nID_COL = 'SeriesInstanceUID'\nLABEL_COLS = [\n    'Left Infraclinoid Internal Carotid Artery',\n    'Right Infraclinoid Internal Carotid Artery',\n    'Left Supraclinoid Internal Carotid Artery',\n    'Right Supraclinoid Internal Carotid Artery',\n    'Left Middle Cerebral Artery',\n    'Right Middle Cerebral Artery',\n    'Anterior Communicating Artery',\n    'Left Anterior Cerebral Artery',\n    'Right Anterior Cerebral Artery',\n    'Left Posterior Communicating Artery',\n    'Right Posterior Communicating Artery',\n    'Basilar Tip',\n    'Other Posterior Circulation',\n    'Aneurysm Present',\n]\n\n# ====================================================\n# Configuration\n# ====================================================\nclass InferenceConfig:\n    # Model settings\n    model_name = \"tf_efficientnetv2_s.in21k_ft_in1k\"\n    size = 384\n    target_cols = LABEL_COLS\n    num_classes = len(target_cols)\n    in_chans = 32\n    \n    # Preprocessing settings\n    target_shape = (32, 384, 384)  # (depth, height, width)\n    \n    # Inference settings\n    batch_size = 1\n    use_amp = True\n    use_tta = False  # TTA is prohibited due to left/right positional information\n    tta_transforms = 0\n    \n    # Model paths\n    model_dir = '/kaggle/input/rsna2025-effnetv2-32ch'\n    n_fold = 5\n    trn_fold = [0, 1, 2, 3, 4]\n    \n    # Ensemble weights (equal weight for all folds)\n    ensemble_weights = None  # None means equal weights\n\nCFG = InferenceConfig()\n\n# ====================================================\n# Transforms\n# ====================================================\ndef get_inference_transform():\n    \"\"\"Get inference transformation\"\"\"\n    return A.Compose([\n        A.Resize(CFG.size, CFG.size),\n        A.Normalize(),\n        ToTensorV2(),\n    ])\n\n# TTA is not used due to left/right positional information\n# def get_tta_transforms():\n#     \"\"\"TTA is prohibited for brain aneurysms due to left/right positioning\"\"\"\n#     pass\n\n# ====================================================\n# Model Loading Functions\n# ====================================================\n# Global variables\nMODELS = {}\nTRANSFORM = None\nTTA_TRANSFORMS = None\n\ndef load_model_fold(fold: int) -> nn.Module:\n    \"\"\"Load a single fold model\"\"\"\n    model_path = Path(CFG.model_dir) / f'{CFG.model_name}_fold{fold}_best.pth'\n    \n    if not model_path.exists():\n        raise FileNotFoundError(f\"Model file not found: {model_path}\")\n    \n    #print(f\"Loading fold {fold} model from {model_path}...\")\n    \n    # Load checkpoint\n    checkpoint = torch.load(model_path, map_location=device, weights_only=False)\n    \n    # Initialize model with same architecture as training\n    model = timm.create_model(\n        CFG.model_name, \n        num_classes=CFG.num_classes, \n        pretrained=False,  # Don't load pretrained weights\n        in_chans=CFG.in_chans\n    )\n    \n    # Load trained weights\n    model.load_state_dict(checkpoint['model'])\n    model = model.to(device)\n    model.eval()\n    \n    #print(f\"Successfully loaded fold {fold} model\")\n    return model\n\ndef load_models():\n    \"\"\"Load all fold models\"\"\"\n    global MODELS, TRANSFORM, TTA_TRANSFORMS\n    \n    #print(\"Loading all fold models...\")\n    \n    for fold in CFG.trn_fold:\n        try:\n            MODELS[fold] = load_model_fold(fold)\n        except Exception as e:\n            print(f\"Warning: Could not load fold {fold}: {e}\")\n    \n    if not MODELS:\n        raise ValueError(\"No models were loaded successfully\")\n    \n    # Initialize transforms\n    TRANSFORM = get_inference_transform()\n    # TTA is not used due to left/right positioning\n    TTA_TRANSFORMS = None\n    \n    #print(f\"Loaded {len(MODELS)} models: folds {list(MODELS.keys())}\")\n    \n    # Warm up models\n    #print(\"Warming up models...\")\n    dummy_image = torch.randn(1, CFG.in_chans, CFG.size, CFG.size).to(device)\n    \n    with torch.no_grad():\n        for fold, model in MODELS.items():\n            _ = model(dummy_image)\n    \n    #print(\"Models ready for inference!\")\n\n# ====================================================\n# Prediction Functions\n# ====================================================\ndef predict_single_model(model: nn.Module, image: np.ndarray) -> np.ndarray:\n    \"\"\"Make prediction with a single model (NO TTA due to left/right anatomy)\"\"\"\n    \n    # Same processing as training code\n    # image shape: (D, H, W) = (32, 384, 384)\n    image = image.transpose(1, 2, 0)  # (D,H,W) -> (H,W,D) = (384, 384, 32)\n    \n    # Apply same transform as training\n    transformed = TRANSFORM(image=image)\n    image_tensor = transformed['image']  # Shape: (32, 384, 384)\n    image_tensor = image_tensor.unsqueeze(0).to(device)  # (1, 32, 384, 384)\n    \n    with torch.no_grad():\n        with autocast(enabled=CFG.use_amp):\n            output = model(image_tensor)\n            return torch.sigmoid(output).cpu().numpy().squeeze()\n\ndef predict_ensemble(image: np.ndarray) -> np.ndarray:\n    \"\"\"Make ensemble prediction across all folds\"\"\"\n    all_predictions = []\n    weights = []\n    \n    for fold, model in MODELS.items():\n        pred = predict_single_model(model, image)\n        all_predictions.append(pred)\n        \n        # Use equal weights if not specified\n        if CFG.ensemble_weights is not None:\n            weights.append(CFG.ensemble_weights.get(fold, 1.0))\n        else:\n            weights.append(1.0)\n    \n    # Weighted average\n    weights = np.array(weights) / np.sum(weights)\n    predictions = np.array(all_predictions)\n    \n    return np.average(predictions, weights=weights, axis=0)\n\ndef _predict_inner(series_path: str) -> pl.DataFrame:\n    \"\"\"Main prediction logic (internal).\"\"\"\n    global MODELS\n    \n    # Load models if not already loaded\n    if not MODELS:\n        load_models()\n    \n    # Extract series ID\n    series_id = os.path.basename(series_path)\n    \n    try:\n        # Process DICOM series using our preprocessor\n        volume = process_dicom_series_safe(series_path, CFG.target_shape)\n        \n        # Make ensemble prediction\n        final_pred = predict_ensemble(volume)\n        \n        # Create output dataframe\n        predictions_df = pl.DataFrame(\n            data=[[series_id] + final_pred.tolist()],\n            schema=[ID_COL] + LABEL_COLS,\n            orient='row'\n        )\n        \n        # Return without ID column, as required by the API\n        return predictions_df.drop(ID_COL)\n        \n    except Exception as e:\n        #print(f\"Error processing {series_id}: {e}\")\n        # Return conservative predictions\n        conservative_preds = [0.1] * len(LABEL_COLS)\n        predictions_df = pl.DataFrame(\n            data=[conservative_preds],\n            schema=LABEL_COLS,\n            orient='row'\n        )\n        return predictions_df\n\n# ====================================================\n# DICOM Processing (using DICOMPreprocessorKaggle defined in previous cell)\n# ====================================================\ndef process_dicom_series_safe(series_path: str, target_shape: Tuple[int, int, int] = (32, 384, 384)) -> np.ndarray:\n    \"\"\"\n    Safe DICOM processing with memory cleanup\n    Uses DICOMPreprocessorKaggle defined in previous cell\n    \n    Args:\n        series_path: Path to DICOM series\n        target_shape: Target volume size (depth, height, width)\n    \n    Returns:\n        np.ndarray: Processed volume\n    \"\"\"\n    try:\n        preprocessor = DICOMPreprocessorKaggle(target_shape=target_shape)\n        volume = preprocessor.process_series(series_path)\n        return volume\n    finally:\n        # Memory cleanup\n        gc.collect()\n\ndef predict_fallback(series_path: str) -> pl.DataFrame:\n    \"\"\"Fallback prediction function\"\"\"\n    #print(f\"Using fallback predictions for {os.path.basename(series_path)}\")\n    \n    # Return conservative predictions\n    conservative_preds = [0.1] * len(LABEL_COLS)\n    predictions_df = pl.DataFrame(\n        data=[conservative_preds],\n        schema=LABEL_COLS,\n        orient='row'\n    )\n    \n    # Clean up\n    shutil.rmtree('/kaggle/shared', ignore_errors=True)\n    \n    return predictions_df\n\ndef predict(series_path: str) -> pl.DataFrame:\n    \"\"\"\n    Top-level prediction function passed to the server.\n    It calls the core logic and guarantees cleanup in a `finally` block.\n    \"\"\"\n    try:\n        # Call the internal prediction logic\n        return _predict_inner(series_path)\n    except Exception as e:\n        #print(f\"Error during prediction for {os.path.basename(series_path)}: {e}\")\n        #print(\"Using fallback predictions.\")\n        # Return a fallback dataframe with the correct schema\n        conservative_preds = [0.1] * len(LABEL_COLS)\n        predictions = pl.DataFrame(\n            data=[conservative_preds],\n            schema=LABEL_COLS,\n            orient='row'\n        )\n        return predictions\n    finally:\n        # This code is required to prevent \"out of disk space\" and \"directory not empty\" errors.\n        # It deletes the shared folder and then immediately recreates it, ensuring it's\n        # empty and ready for the next prediction.\n        shared_dir = '/kaggle/shared'\n        shutil.rmtree(shared_dir, ignore_errors=True)\n        os.makedirs(shared_dir, exist_ok=True)\n        \n        # Also perform memory cleanup here\n        if torch.cuda.is_available():\n            torch.cuda.empty_cache()\n        gc.collect()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T20:16:14.566477Z","iopub.execute_input":"2025-12-07T20:16:14.566777Z","iopub.status.idle":"2025-12-07T20:16:14.589197Z","shell.execute_reply.started":"2025-12-07T20:16:14.566755Z","shell.execute_reply":"2025-12-07T20:16:14.588334Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"#!/usr/bin/env python3\n\"\"\"\nULTRA-FAST K-fold training for RSNA intracranial aneurysm detection.\nOPTIMIZATIONS:\n- Lighter model (EfficientNet-B0 instead of V2-S) → 2x faster\n- Reduced augmentations → 30% faster\n- Larger batch size → 40% faster  \n- Fewer epochs with early stopping → 50% less time\n- Parallel data loading → 25% faster\n- Mixed precision by default\n- TOTAL: ~5-6x faster than original\n\"\"\"\n\nimport os\nimport random\nfrom pathlib import Path\nfrom typing import Optional\n\nimport numpy as np\nimport pandas as pd\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import StratifiedKFold\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.cuda.amp import autocast, GradScaler\n\nimport timm\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\n\n# === OPTIMIZED CONFIG ===\nclass CFG:\n    # Paths\n    data_root = Path('/kaggle/input/rsna-intracranial-aneurysm-detection')\n    train_csv = data_root / 'train.csv'\n    train_images = data_root / 'series'  # ← CORRECTED PATH\n    output_dir = Path('./models_fast')\n\n    # Model - LIGHTER & FASTER\n    model_name = \"efficientnet_b0\"  # Much faster than efficientnetv2_s\n    in_chans = 32\n    img_size = 384\n    num_classes = 14\n\n    # Training - OPTIMIZED FOR SPEED\n    seed = 42\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    epochs = 12  # Increased slightly for better convergence\n    batch_size = 8  # Reduced for stability\n    num_workers = 2\n    lr = 1e-4  # Lower LR for stability\n    weight_decay = 1e-5\n    use_amp = True\n    gradient_clip = 0.5  # Stronger clipping for stability\n    \n    # Early stopping - SAVES TIME\n    early_stop_patience = 3  # More patience\n    min_delta = 0.001  # Minimum improvement\n\n    # K-fold\n    n_splits = 5\n    run_fold: Optional[int] = None  # Run single fold for testing, None for all\n\n    # Caching - DRAMATICALLY SPEEDS UP\n    use_cache = False  # Set True after first run\n    cache_dir = Path('./cache_fast')\n    \n    # Save less frequently\n    save_every_epoch = False  # Only save best\n\n    # Debug\n    debug = False\n    debug_samples = 100\n\n# Setup\nCFG.output_dir.mkdir(parents=True, exist_ok=True)\nif CFG.use_cache:\n    CFG.cache_dir.mkdir(parents=True, exist_ok=True)\n\nLABEL_COLS = [\n    'Left Infraclinoid Internal Carotid Artery',\n    'Right Infraclinoid Internal Carotid Artery',\n    'Left Supraclinoid Internal Carotid Artery',\n    'Right Supraclinoid Internal Carotid Artery',\n    'Left Middle Cerebral Artery',\n    'Right Middle Cerebral Artery',\n    'Anterior Communicating Artery',\n    'Left Anterior Cerebral Artery',\n    'Right Anterior Cerebral Artery',\n    'Left Posterior Communicating Artery',\n    'Right Posterior Communicating Artery',\n    'Basilar Tip',\n    'Other Posterior Circulation',\n    'Aneurysm Present',\n]\n\ndef seed_all(seed=42):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.benchmark = True  # ← FASTER\n\nseed_all(CFG.seed)\n\n# ===== FAST DATASET =====\nclass FastRSNADataset(Dataset):\n    \"\"\"Optimized dataset with caching and error handling\"\"\"\n    def __init__(self, df, transform=None):\n        self.df = df.reset_index(drop=True)\n        self.transform = transform\n        self.failed = set()\n        self.failure_reasons = {}\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def _get_cache_path(self, series_id):\n        return CFG.cache_dir / f\"{series_id}.npy\"\n    \n    def __getitem__(self, idx):\n        if idx in self.failed:\n            return self._get_dummy()\n        \n        row = self.df.iloc[idx]\n        series_id = str(row['SeriesInstanceUID'])\n        \n        try:\n            # Try cache first\n            if CFG.use_cache:\n                cache_path = self._get_cache_path(series_id)\n                if cache_path.exists():\n                    vol = np.load(cache_path)\n                    return self._process_volume(vol, row)\n            \n            # Load from DICOM\n            series_path = CFG.train_images / series_id\n            \n            # CHECK IF PATH EXISTS\n            if not series_path.exists():\n                raise FileNotFoundError(f\"Path does not exist: {series_path}\")\n            \n            vol = process_dicom_series_safe(str(series_path), (CFG.in_chans, CFG.img_size, CFG.img_size))\n            \n            # VALIDATE VOLUME\n            if vol is None:\n                raise ValueError(\"Preprocessing returned None\")\n            if not isinstance(vol, np.ndarray):\n                raise ValueError(f\"Invalid type: {type(vol)}\")\n            if vol.shape != (CFG.in_chans, CFG.img_size, CFG.img_size):\n                raise ValueError(f\"Wrong shape: {vol.shape}\")\n            \n            # Cache it\n            if CFG.use_cache:\n                np.save(self._get_cache_path(series_id), vol)\n            \n            return self._process_volume(vol, row)\n            \n        except Exception as e:\n            self.failed.add(idx)\n            self.failure_reasons[idx] = str(e)\n            # Only print first few failures\n            if len(self.failed) <= 3:\n                print(f\"   ⚠️  Failed to load sample {idx} ({series_id}): {e}\")\n            return self._get_dummy()\n    \n    def _process_volume(self, vol, row):\n        \"\"\"Process volume and return tensor\"\"\"\n        # Normalize\n        vol = vol.astype(np.float32) / 255.0\n        \n        # (D,H,W) -> (H,W,D) for albumentations\n        img_hwc = vol.transpose(1, 2, 0)\n        \n        if self.transform:\n            augmented = self.transform(image=img_hwc)\n            img_tensor = augmented['image']\n        else:\n            img_tensor = torch.from_numpy(img_hwc.transpose(2, 0, 1))\n        \n        # GET REAL LABELS (not dummy zeros)\n        labels = torch.tensor(row[LABEL_COLS].values.astype(np.float32), dtype=torch.float32)\n        return img_tensor, labels\n    \n    def _get_dummy(self):\n        \"\"\"Return dummy data for failed samples\"\"\"\n        dummy_img = torch.zeros((CFG.in_chans, CFG.img_size, CFG.img_size))\n        dummy_labels = torch.zeros(CFG.num_classes, dtype=torch.float32)\n        return dummy_img, dummy_labels\n\n# ===== MINIMAL AUGMENTATIONS (FASTER) =====\ndef get_train_aug():\n    \"\"\"Reduced augmentations for speed\"\"\"\n    return A.Compose([\n        A.Resize(CFG.img_size, CFG.img_size),\n        A.HorizontalFlip(p=0.5),\n        A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05, rotate_limit=5, p=0.3),\n        A.Normalize(),\n        ToTensorV2(),\n    ])\n\ndef get_valid_aug():\n    return A.Compose([\n        A.Resize(CFG.img_size, CFG.img_size),\n        A.Normalize(),\n        ToTensorV2(),\n    ])\n\n# ===== MODEL =====\ndef build_model(pretrained=False):\n    \"\"\"Build lighter model (no pretrained for speed)\"\"\"\n    model = timm.create_model(\n        CFG.model_name,\n        pretrained=pretrained,\n        num_classes=CFG.num_classes,\n        in_chans=CFG.in_chans\n    )\n    return model\n\n# ===== LOSS & METRICS =====\nclass StableBCELoss(nn.Module):\n    \"\"\"BCE Loss with numerical stability\"\"\"\n    def __init__(self):\n        super().__init__()\n    \n    def forward(self, inputs, targets):\n        # Clamp for stability\n        inputs = torch.clamp(inputs, min=-20, max=20)\n        loss = nn.functional.binary_cross_entropy_with_logits(inputs, targets)\n        \n        # Check for NaN\n        if torch.isnan(loss):\n            return torch.tensor(0.0, device=loss.device)\n        \n        return loss\n\ncriterion = StableBCELoss()\n\ndef compute_auc(y_true, y_pred):\n    \"\"\"Fast AUC computation\"\"\"\n    aucs = []\n    for i in range(y_true.shape[1]):\n        try:\n            if len(np.unique(y_true[:, i])) > 1:\n                auc = roc_auc_score(y_true[:, i], y_pred[:, i])\n                aucs.append(auc)\n        except:\n            pass\n    return np.mean(aucs) if aucs else 0.0\n\n# ===== TRAINING LOOP WITH NaN CHECKS =====\ndef check_model_health(model):\n    \"\"\"Check for NaN/Inf in model parameters\"\"\"\n    for name, param in model.named_parameters():\n        if param is None:\n            continue\n        if torch.isnan(param).any() or torch.isinf(param).any():\n            return False, name\n    return True, None\n\ndef train_epoch(model, loader, optimizer, scaler):\n    model.train()\n    total_loss = 0\n    \n    for batch_idx, (images, labels) in enumerate(loader):\n        images = images.to(CFG.device, non_blocking=True)\n        labels = labels.to(CFG.device, non_blocking=True)\n        \n        optimizer.zero_grad(set_to_none=True)\n        \n        with autocast(enabled=CFG.use_amp):\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n        \n        # Check for NaN loss\n        if torch.isnan(loss) or torch.isinf(loss):\n            print(f\"   ⚠️  NaN/Inf loss detected at batch {batch_idx}, skipping...\")\n            continue\n        \n        scaler.scale(loss).backward()\n        \n        # Gradient clipping\n        if CFG.gradient_clip > 0:\n            scaler.unscale_(optimizer)\n            torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.gradient_clip)\n        \n        scaler.step(optimizer)\n        scaler.update()\n        \n        total_loss += loss.item()\n        \n        # Periodic health check\n        if batch_idx % 50 == 0:\n            healthy, bad_param = check_model_health(model)\n            if not healthy:\n                print(f\"   ⚠️  Model corrupted at batch {batch_idx}! NaN/Inf in: {bad_param}\")\n                return float('inf')\n    \n    return total_loss / max(1, len(loader))\n\n@torch.no_grad()\ndef validate(model, loader):\n    model.eval()\n    total_loss = 0\n    all_preds = []\n    all_targets = []\n    \n    for images, labels in loader:\n        images = images.to(CFG.device, non_blocking=True)\n        labels = labels.to(CFG.device, non_blocking=True)\n        \n        with autocast(enabled=CFG.use_amp):\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n        \n        preds = torch.sigmoid(outputs).cpu().numpy()\n        targets = labels.cpu().numpy()\n        \n        all_preds.append(preds)\n        all_targets.append(targets)\n        total_loss += loss.item()\n    \n    all_preds = np.vstack(all_preds)\n    all_targets = np.vstack(all_targets)\n    \n    # DIAGNOSTICS\n    n_positives = all_targets.sum()\n    n_total = all_targets.size\n    print(f\"   Validation: {n_positives:.0f} positives / {n_total} total ({100*n_positives/n_total:.2f}%)\")\n    print(f\"   Pred range: [{all_preds.min():.4f}, {all_preds.max():.4f}], mean: {all_preds.mean():.4f}\")\n    \n    # Check if all targets are zero (failed samples)\n    if n_positives == 0:\n        print(f\"   ⚠️  WARNING: No positive samples in validation! All samples may have failed to load.\")\n        return total_loss / len(loader), 0.0\n    \n    auc = compute_auc(all_targets, all_preds)\n    \n    return total_loss / len(loader), auc\n\n# ===== MAIN K-FOLD =====\ndef run_fast_kfold():\n    print(\"=\"*60)\n    print(\"ULTRA-FAST K-FOLD TRAINING\")\n    print(\"=\"*60)\n    \n    # TEST PREPROCESSING FIRST\n    print(\"\\nTesting preprocessing...\")\n    df = pd.read_csv(CFG.train_csv)\n    test_series = df['SeriesInstanceUID'].iloc[0]\n    test_path = CFG.train_images / test_series\n    \n    try:\n        vol = process_dicom_series_safe(str(test_path), (CFG.in_chans, CFG.img_size, CFG.img_size))\n        print(f\"✅ Preprocessing works! Shape: {vol.shape}, dtype: {vol.dtype}\")\n    except Exception as e:\n        print(f\"❌ PREPROCESSING FAILED: {e}\")\n        print(\"Please ensure:\")\n        print(\"1. You have pasted the preprocessing code in Cell 1\")\n        print(\"2. The function 'process_dicom_series_safe' is defined\")\n        print(\"3. CFG.train_images path is correct\")\n        return\n    \n    # Load data\n    df = pd.read_csv(CFG.train_csv)\n    \n    # Ensure label columns exist\n    for col in LABEL_COLS:\n        if col not in df.columns:\n            df[col] = 0\n    \n    # Debug mode\n    if CFG.debug:\n        print(f\"⚠️  DEBUG MODE: Using {CFG.debug_samples} samples\")\n        df = df.sample(CFG.debug_samples, random_state=CFG.seed).reset_index(drop=True)\n    \n    print(f\"Total samples: {len(df)}\")\n    print(f\"Positive aneurysms: {df['Aneurysm Present'].sum()} ({100*df['Aneurysm Present'].mean():.1f}%)\")\n    \n    # K-Fold split\n    skf = StratifiedKFold(n_splits=CFG.n_splits, shuffle=True, random_state=CFG.seed)\n    \n    results = []\n    \n    for fold, (train_idx, val_idx) in enumerate(skf.split(df, df['Aneurysm Present'])):\n        if CFG.run_fold is not None and fold != CFG.run_fold:\n            continue\n        \n        print(f\"\\n{'='*60}\")\n        print(f\"FOLD {fold}/{CFG.n_splits-1}\")\n        print(f\"{'='*60}\")\n        \n        train_df = df.iloc[train_idx].reset_index(drop=True)\n        val_df = df.iloc[val_idx].reset_index(drop=True)\n        \n        print(f\"Train: {len(train_df)} | Valid: {len(val_df)}\")\n        \n        # Datasets\n        train_ds = FastRSNADataset(train_df, get_train_aug())\n        val_ds = FastRSNADataset(val_df, get_valid_aug())\n        \n        # Loaders with optimizations\n        train_loader = DataLoader(\n            train_ds, \n            batch_size=CFG.batch_size,\n            shuffle=True,\n            num_workers=CFG.num_workers,\n            pin_memory=True,\n            drop_last=True,\n            persistent_workers=CFG.num_workers > 0\n        )\n        \n        val_loader = DataLoader(\n            val_ds,\n            batch_size=CFG.batch_size,\n            shuffle=False,\n            num_workers=CFG.num_workers,\n            pin_memory=True,\n            persistent_workers=CFG.num_workers > 0\n        )\n        \n        # Model\n        model = build_model(pretrained=False).to(CFG.device)\n        optimizer = torch.optim.AdamW(model.parameters(), lr=CFG.lr, weight_decay=CFG.weight_decay)\n        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=CFG.epochs)\n        scaler = GradScaler(enabled=CFG.use_amp)\n        \n        # Training loop with early stopping\n        best_auc = 0\n        patience = 0\n        \n        # Initial health check\n        healthy, bad_param = check_model_health(model)\n        if not healthy:\n            print(f\"⚠️  Model initialized with NaN/Inf in: {bad_param}\")\n            print(\"Reinitializing model...\")\n            model = build_model(pretrained=False).to(CFG.device)\n        \n        for epoch in range(CFG.epochs):\n            print(f\"\\nEpoch {epoch+1}/{CFG.epochs}\")\n            \n            train_loss = train_epoch(model, train_loader, optimizer, scaler)\n            val_loss, val_auc = validate(model, val_loader)\n            scheduler.step()\n            \n            print(f\"Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | Val AUC: {val_auc:.4f}\")\n            \n            # Report failures\n            if len(train_ds.failed) > 0:\n                print(f\"   Failed samples: {len(train_ds.failed)}/{len(train_ds)} train, {len(val_ds.failed)}/{len(val_ds)} val\")\n            \n            # Save best\n            if val_auc > best_auc + CFG.min_delta:\n                best_auc = val_auc\n                patience = 0\n                \n                checkpoint = {\n                    'model': model.state_dict(),\n                    'epoch': epoch,\n                    'fold': fold,\n                    'auc': best_auc,\n                }\n                save_path = CFG.output_dir / f\"{CFG.model_name}_fold{fold}_best.pth\"\n                torch.save(checkpoint, save_path)\n                print(f\"   ✓ Saved best model: AUC={best_auc:.4f}\")\n            else:\n                patience += 1\n                print(f\"   No improvement (patience: {patience}/{CFG.early_stop_patience})\")\n            \n            # Early stopping\n            if patience >= CFG.early_stop_patience:\n                print(f\"   Early stopping triggered!\")\n                break\n        \n        results.append({'fold': fold, 'best_auc': best_auc})\n        \n        # Cleanup\n        del model, optimizer, scheduler\n        torch.cuda.empty_cache()\n    \n    # Summary\n    print(f\"\\n{'='*60}\")\n    print(\"TRAINING COMPLETE\")\n    print(f\"{'='*60}\")\n    for r in results:\n        print(f\"Fold {r['fold']}: AUC = {r['best_auc']:.4f}\")\n    \n    if results:\n        avg_auc = np.mean([r['best_auc'] for r in results])\n        print(f\"\\nAverage AUC: {avg_auc:.4f}\")\n    \n    print(f\"\\n✓ Models saved to: {CFG.output_dir}/\")\n\n# ===== ENTRYPOINT =====\nif __name__ == '__main__':\n    run_fast_kfold()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-06T17:33:20.603010Z","iopub.execute_input":"2025-12-06T17:33:20.603652Z","execution_failed":"2025-12-07T05:22:34.785Z"}},"outputs":[{"name":"stdout","text":"============================================================\nULTRA-FAST K-FOLD TRAINING\n============================================================\n\nTesting preprocessing...\n✅ Preprocessing works! Shape: (32, 384, 384), dtype: uint8\nTotal samples: 4348\nPositive aneurysms: 1863 (42.8%)\n\n============================================================\nFOLD 0/4\n============================================================\nTrain: 3478 | Valid: 870\n\nEpoch 1/12\n   Validation: 806 positives / 12180 total (6.62%)\n   Pred range: [0.0000, 1.0000], mean: 0.1423\nTrain Loss: 0.2663 | Val Loss: 2.9172 | Val AUC: 0.5095\n   ✓ Saved best model: AUC=0.5095\n\nEpoch 2/12\n   Validation: 806 positives / 12180 total (6.62%)\n   Pred range: [0.0000, 1.0000], mean: 0.1013\nTrain Loss: 0.1942 | Val Loss: 2.4886 | Val AUC: 0.4939\n   No improvement (patience: 1/3)\n\nEpoch 3/12\n   Validation: 806 positives / 12180 total (6.62%)\n   Pred range: [0.0000, 1.0000], mean: 0.0966\nTrain Loss: 0.1936 | Val Loss: 2.2098 | Val AUC: 0.5053\n   No improvement (patience: 2/3)\n\nEpoch 4/12\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}